# -*- coding: utf-8 -*-
"""Accidents_Borough.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JPd02L9u4k7x7C0wLoLp7ziJUcONNTES

This python file contains the Borough level analysis along with the EDA, and the modelling. This python file was run on google colab, so please replace the file path with your local file path. Pycaret library has been utilized for the modelling, so you can install using "pip install pycaret" to download the latest version.
"""

!pip install pycaret

from google.colab import drive

drive.mount('/content/drive')

import pandas as pd
path = "/content/drive/MyDrive/Accidents.csv"
df = pd.read_csv(path)

#%%[markdown]
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# %%

df.head()
# %%
#Cleaning the NA or empty values in the Borough column.
df_clean = df.dropna(subset=['BOROUGH'])


# %%
import plotly.graph_objects as go
from plotly.offline import iplot

# Calculate the sums for each borough
sums_df = df.groupby('BOROUGH', as_index=False).sum()

# Add a total column
sums_df['TOTAL'] = sums_df['NUMBER OF CYCLIST KILLED'] + sums_df['NUMBER OF MOTORIST KILLED'] + sums_df['NUMBER OF PEDESTRIANS KILLED']

# Calculate percentages
sums_df['CYCLIST_KILLED_PERCENT'] = (sums_df['NUMBER OF CYCLIST KILLED'] / sums_df['TOTAL']) * 100
sums_df['MOTORIST_KILLED_PERCENT'] = (sums_df['NUMBER OF MOTORIST KILLED'] / sums_df['TOTAL']) * 100
sums_df['PEDESTRIANS_KILLED_PERCENT'] = (sums_df['NUMBER OF PEDESTRIANS KILLED'] / sums_df['TOTAL']) * 100

# Create traces for each category with percentages
trace1 = go.Bar(
    x=sums_df['BOROUGH'],
    y=sums_df['CYCLIST_KILLED_PERCENT'],
    name='Cyclist Killed',
    marker=dict(color='blue')
)

trace2 = go.Bar(
    x=sums_df['BOROUGH'],
    y=sums_df['MOTORIST_KILLED_PERCENT'],
    name='Motorist Killed',
    marker=dict(color='orange')
)

trace3 = go.Bar(
    x=sums_df['BOROUGH'],
    y=sums_df['PEDESTRIANS_KILLED_PERCENT'],
    name='Pedestrians Killed',
    marker=dict(color='red')
)

data = [trace1, trace2, trace3]

layout = go.Layout(
    title='Average Percentage of Deaths by Borough',
    xaxis=dict(title='Borough'),
    yaxis=dict(title='Percentage of Deaths', tickformat='.2f'),
    barmode='stack'
)

fig = go.Figure(data=data, layout=layout)
iplot(fig)

# %%
import plotly.express as px
df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])
df['YEAR'] = df['CRASH DATE'].dt.year

# Group by 'YEAR' and 'BOROUGH' and calculate the average number of persons injured
# Since we're using mock data, we'll just count the number of incidents per year for simplicity
df_average = df.groupby(['YEAR', 'BOROUGH']).agg({'NUMBER OF PERSONS INJURED': 'mean'}).reset_index()

# Create the line chart
fig = px.line(df_average, x='YEAR', y='NUMBER OF PERSONS INJURED', color='BOROUGH',
              labels={'PERSONS_INJURED': 'Average Number of Persons Injured'},
              title='Average Number of Persons Injured by Year and Borough')

fig.update_layout(
    width=600,  # You can adjust this value as needed
)
# Update the x-axis to show every year
fig.update_xaxes(dtick=1)

# Show the plot
fig.show()
# %%
# %%
import plotly.express as px
df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])
df['YEAR'] = df['CRASH DATE'].dt.year

# Group by 'YEAR' and 'BOROUGH' and calculate the average number of persons injured
# Since we're using mock data, we'll just count the number of incidents per year for simplicity
df_average = df.groupby(['YEAR', 'BOROUGH']).agg({'NUMBER OF PERSONS KILLED': 'mean'}).reset_index()

# Create the line chart
fig = px.line(df_average, x='YEAR', y='NUMBER OF PERSONS KILLED', color='BOROUGH',
              labels={'PERSONS_INJURED': 'Average Number of Persons Killed'},
              title='Average Number of Persons Killed by Year and Borough')

fig.update_layout(
    width=600,  # You can adjust this value as needed
)
# Update the x-axis to show every year
fig.update_xaxes(dtick=1)

# Show the plot
fig.show()
# %%

df.head()

import pandas as pd
from scipy import stats



# First, we calculate the average number of people killed in each category.
# This assumes that 'BOROUGH' and 'YEAR' are also columns in your DataFrame.
averages = df.groupby(['BOROUGH', 'YEAR']).agg({
    'NUMBER OF CYCLIST KILLED': 'mean',
    'NUMBER OF PEDESTRIANS KILLED': 'mean',
    'NUMBER OF MOTORIST KILLED': 'mean'
}).reset_index()


# Assuming 'averages' is your DataFrame after the groupby and aggregation
# Replace 'BOROUGH' with the appropriate column name if different

# ANOVA for Cyclist Killed
f_val_cyclist, p_val_cyclist = stats.f_oneway(*[group["NUMBER OF CYCLIST KILLED"].values for name, group in averages.groupby("BOROUGH")])
print(f"ANOVA test for Number of Cyclist Killed: F-value = {f_val_cyclist}, P-value = {p_val_cyclist}")

# ANOVA for Pedestrians Killed
f_val_pedestrian, p_val_pedestrian = stats.f_oneway(*[group["NUMBER OF PEDESTRIANS KILLED"].values for name, group in averages.groupby("BOROUGH")])
print(f"ANOVA test for Number of Pedestrians Killed: F-value = {f_val_pedestrian}, P-value = {p_val_pedestrian}")

# ANOVA for Motorists Killed
f_val_motorist, p_val_motorist = stats.f_oneway(*[group["NUMBER OF MOTORIST KILLED"].values for name, group in averages.groupby("BOROUGH")])
print(f"ANOVA test for Number of Motorist Killed: F-value = {f_val_motorist}, P-value = {p_val_motorist}")

import pandas as pd
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Assuming 'averages' is your DataFrame
# Update 'BOROUGH' and 'NUMBER OF MOTORIST KILLED' to match your column names if different

# Perform Tukey's HSD test for 'Number of Motorist Killed'
tukey_results = pairwise_tukeyhsd(endog=averages['NUMBER OF MOTORIST KILLED'], groups=averages['BOROUGH'], alpha=0.05)

# Print the results
print(tukey_results)

tukey_results.plot_simultaneous(figsize=(10, 8))

# Adding a title to the plot
plt.title('Tukey HSD Test Result - Multiple Comparison of Means')

# Showing the plot
plt.show()

df.head()

# %%
conditions = [
    (df['NUMBER OF PERSONS INJURED'] == 0),
    (df['NUMBER OF PERSONS INJURED'] > 0)
]
df['BOROUGH'] = df['BOROUGH'].fillna('Other')
df['BOROUGH'] = df['BOROUGH'].replace(0, 'Other')
values = ['No Injury', 'Injury']

df['SEVERITY'] = np.select(conditions, values, default='Others')

# %%
df.head()
# %%
df['SEVERITY'] = df['SEVERITY'].map({'Injury': 1, 'No Injury': 0})
# %%
# Mapping 'Injury' to 1 and 'No Injury' to 0
#mapped_values = df['VEHICLE TYPE CODE 1'].map({'Fatigued/Drowsy': 0, 'Driver Inexperience': 1,'Alcohol Involvement':2,'Lost Consciousness':3,'Drugs Illegal':4})
#df['VEHICLE TYPE CODE 1'] = mapped_values.fillna(5)
top_factors = [
    'Passing or Lane Usage Improper',
    'Driver Inattention/Distraction',
    'Failure to Yield Right-of-Way',
    'Following Too Closely',
    'Backing Unsafely',
]

# One-hot encode the top factors
top_factors_encoded = pd.get_dummies(df['CONTRIBUTING FACTOR VEHICLE 1'].apply(lambda x: x if x in top_factors else 'Other'))
encoded_df = pd.get_dummies(df, columns=['BOROUGH'])
# Combine the encoded DataFrame back with the original DataFrame
df_combined = pd.concat([df, top_factors_encoded,encoded_df], axis=1)

# If you want to drop the original 'CONTRIBUTING FACTOR VEHICLE 1' column, you can do so
# df_combined.drop('CONTRIBUTING FACTOR VEHICLE 1', axis=1, inplace=True)

print(df_combined.head())
# %%
#df['VEHICLE TYPE CODE 1'].unique
# %%

# Remove duplicate columns based on column names
df_combined = df_combined.loc[:,~df_combined.columns.duplicated()]

print(df_combined.head())

df_combined.head(15)
# %%
df_combined['CRASH DATE'] = pd.to_datetime(df_combined['CRASH DATE'])

# Extract year, month, and day from 'CRASH DATE'
df_combined['Year'] = df_combined['CRASH DATE'].dt.year
df_combined['Month'] = df_combined['CRASH DATE'].dt.month
df_combined['Day'] = df_combined['CRASH DATE'].dt.day

# Ensure 'CRASH TIME' is a string
df_combined['CRASH TIME'] = df_combined['CRASH TIME'].astype(str)

# Extract hour from 'CRASH TIME'
df_combined['Hour'] = df_combined['CRASH TIME'].str.split(':').str[0].astype(int)

# Display the DataFrame to verify the changes
print(df_combined.head())
# %%
correlation_matrix = df_combined[['BOROUGH_BRONX',  'BOROUGH_BROOKLYN' ,'BOROUGH_MANHATTAN', 'BOROUGH_Other' ,'BOROUGH_QUEENS' ,'BOROUGH_STATEN ISLAND', 'Year', 'Month', 'Hour', 'SEVERITY', 'Passing or Lane Usage Improper',
    'Driver Inattention/Distraction',
    'Failure to Yield Right-of-Way',
    'Following Too Closely',
    'Backing Unsafely','Other']].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)

# Setting title and labels for axes
plt.title('Correlation Matrix Heatmap')
plt.xlabel('Variables')
plt.ylabel('Variables')

# Display the heatmap
plt.show()
# %%
df_combined = df_combined.dropna(subset=['SEVERITY'])

from pycaret.classification import *
df1 = df_combined[['BOROUGH_BRONX',  'BOROUGH_BROOKLYN' ,'BOROUGH_MANHATTAN', 'BOROUGH_Other' ,'BOROUGH_QUEENS' ,'BOROUGH_STATEN ISLAND', 'Year', 'Month', 'Hour', 'SEVERITY', 'Passing or Lane Usage Improper',
    'Driver Inattention/Distraction',
    'Failure to Yield Right-of-Way',
    'Following Too Closely',
    'Backing Unsafely','Other']]
# Assuming df is your DataFrame and 'target' is the name of your target column
clf = setup(data=df1, target='SEVERITY', session_id=123)

#%%
  # dt: Decision Tree, rf: Random Forest, et: Extra Trees
#dt_model = create_model('dt')  # Decision Tree
rf_model = create_model('rf')  # Random Forest
#et_model = create_model('et')  # Extra Trees


# %%
#evaluate_model(dt_model)

evaluate_model(rf_model)

averages = df.groupby(['BOROUGH', 'YEAR']).agg({
    'NUMBER OF CYCLIST INJURED': 'mean',
    'NUMBER OF PEDESTRIANS INJURED': 'mean',
    'NUMBER OF MOTORIST INJURED': 'mean'
}).reset_index()
f_val_cyclist, p_val_cyclist = stats.f_oneway(*[group["NUMBER OF CYCLIST INJURED"].values for name, group in averages.groupby("BOROUGH")])
print(f"ANOVA test for Number of Cyclist Injured: F-value = {f_val_cyclist}, P-value = {p_val_cyclist}")

# ANOVA for Pedestrians Injured
f_val_pedestrian, p_val_pedestrian = stats.f_oneway(*[group["NUMBER OF PEDESTRIANS INJURED"].values for name, group in averages.groupby("BOROUGH")])
print(f"ANOVA test for Number of Pedestrians Injured: F-value = {f_val_pedestrian}, P-value = {p_val_pedestrian}")

# ANOVA for Motorists Injured
f_val_motorist, p_val_motorist = stats.f_oneway(*[group["NUMBER OF MOTORIST INJURED"].values for name, group in averages.groupby("BOROUGH")])
print(f"ANOVA test for Number of Motorist Injured: F-value = {f_val_motorist}, P-value = {p_val_motorist}")

tukey_results = pairwise_tukeyhsd(endog=averages['NUMBER OF PEDESTRIANS INJURED'], groups=averages['BOROUGH'], alpha=0.05)

# Print the results
print(tukey_results)

tukey_results.plot_simultaneous(figsize=(10, 8))

# Adding a title to the plot
plt.title('Tukey HSD Test Result - Multiple Comparison of Means')

# Showing the plot
plt.show()

sums_df = df.groupby('BOROUGH', as_index=False).sum()

# Add a total column
sums_df['TOTAL'] = sums_df['NUMBER OF CYCLIST INJURED'] + sums_df['NUMBER OF MOTORIST KILLED'] + sums_df['NUMBER OF PEDESTRIANS KILLED']

# Calculate percentages
sums_df['CYCLIST_KILLED_PERCENT'] = (sums_df['NUMBER OF CYCLIST KILLED'] / sums_df['TOTAL']) * 100
sums_df['MOTORIST_KILLED_PERCENT'] = (sums_df['NUMBER OF MOTORIST KILLED'] / sums_df['TOTAL']) * 100
sums_df['PEDESTRIANS_KILLED_PERCENT'] = (sums_df['NUMBER OF PEDESTRIANS KILLED'] / sums_df['TOTAL']) * 100

# Create traces for each category with percentages
trace1 = go.Bar(
    x=sums_df['BOROUGH'],
    y=sums_df['CYCLIST_KILLED_PERCENT'],
    name='Cyclist Killed',
    marker=dict(color='blue')
)

trace2 = go.Bar(
    x=sums_df['BOROUGH'],
    y=sums_df['MOTORIST_KILLED_PERCENT'],
    name='Motorist Killed',
    marker=dict(color='orange')
)

trace3 = go.Bar(
    x=sums_df['BOROUGH'],
    y=sums_df['PEDESTRIANS_KILLED_PERCENT'],
    name='Pedestrians Killed',
    marker=dict(color='red')
)

data = [trace1, trace2, trace3]

layout = go.Layout(
    title='Average Percentage of Deaths by Borough',
    xaxis=dict(title='Borough'),
    yaxis=dict(title='Percentage of Deaths', tickformat='.2f'),
    barmode='stack'
)

fig = go.Figure(data=data, layout=layout)
iplot(fig)

# %%

